{"./":{"url":"./","title":"前言","keywords":"","body":" 前言 前言 https://www.elastic.co/cn/elasticsearch Elasticsearch 是一个基于 Apache Lucene 构建的开源搜索和分析引擎，它专注于实时数据的存储、检索和分析。Elasticsearch 被设计成可水平扩展，能够处理大规模数据并提供快速的检索和分析能力。它通常用于日志和事件数据分析、全文搜索以及其他需要快速和灵活搜索能力的场景。Elasticsearch 提供丰富的 API，用于索引和查询数据，因此受到了开发人员和处理大型数据集的组织的欢迎。 Elasticsearch 是一个分布式、高扩展、高实时的搜索与数据分析引擎。它能很方便的使大量数据具有搜索、分析和探索的能力。充分利用Elasticsearch的水平伸缩性，能使数据在生产环境变得更有价值。Elasticsearch 的实现原理主要分为以下几个步骤，首先用户将数据提交到Elasticsearch 数据库中，再通过分词控制器去将对应的语句分词，将其权重和分词结果一并存入数据，当用户搜索数据时候，再根据权重将结果排名，打分，再将返回结果呈现给用户。 Elasticsearch是与名为Logstash的数据收集和日志解析引擎以及名为Kibana的分析和可视化平台一起开发的。这三个产品被设计成一个集成解决方案，称为“Elastic Stack”（以前称为“ELK stack”）。 Elasticsearch可以用于搜索各种文档。它提供可扩展的搜索，具有接近实时的搜索，并支持多租户。Elasticsearch是分布式的，这意味着索引可以被分成分片，每个分片可以有0个或多个副本。每个节点托管一个或多个分片，并充当协调器将操作委托给正确的分片。再平衡和路由是自动完成的。相关数据通常存储在同一个索引中，该索引由一个或多个主分片和零个或多个复制分片组成。一旦创建了索引，就不能更改主分片的数量。 Elasticsearch使用Lucene，并试图通过JSON和Java API提供其所有特性。它支持facetting和percolating，如果新文档与注册查询匹配，这对于通知非常有用。另一个特性称为“网关”，处理索引的长期持久性；例如，在服务器崩溃的情况下，可以从网关恢复索引。Elasticsearch支持实时GET请求，适合作为NoSQL数据存储，但缺少分布式事务。 强大的搜索能力： Elasticsearch 基于 Lucene 构建，提供了强大的全文搜索功能，支持复杂的查询和分析。 实时性能： Elasticsearch 提供了快速的实时查询和分析能力，适用于需要即时反馈的应用场景。 可扩展性： Elasticsearch 能够轻松地水平扩展，可以处理大规模的数据集。 开发友好： Elasticsearch 提供了简单易用的 RESTful API，方便开发人员进行数据的索引、查询和管理。 丰富的生态系统： Elasticsearch 生态系统包括了各种插件和工具，支持多种数据源的集成和数据处理。 多功能性： Elasticsearch 不仅仅用于搜索和分析，还可以用作日志收集、监控数据分析、实时推荐等多种用途。 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"es-jie-shao.html":{"url":"es-jie-shao.html","title":"ES介绍","keywords":"","body":" ES介绍1. ES功能特点 1.1. ES是什么 1.2. ES主要功能 2. ES主要特点 2.1. 分片与集群 2.2. 自动索引 2.3. 搜索是近实时的 2.4. ES优缺点 3. ES核心概念 3.1. 索引（index）库 3.2. 类型（type）表 3.3. 文档（document）行 3.4. Lucene Index 3.5. 段（Segment） 3.6. 提交点（commit point） 3.7. 映射 3.8. Shard 分片 3.9. Replica 副本 3.10. Cluster集群 3.11. Node节点 4. ES使用 4.1. 分片的设定 4.2. ES数据近实时问题 ES介绍 1. ES功能特点 1.1. ES是什么 特点: 非关系型、搜索引擎、近实时搜索与分析、高可用、天然分布式、横向可扩展 ES是一个分布式、可扩展、实时的搜索与数据分析引擎 ES不仅仅只是全文搜索，还支持结构化搜索、数据分析、复杂的语言处理、地理位置和对象间关联关系等 ES的底层依赖Lucene，Lucene可以说是当下最先进、高性能、全功能的搜索引擎库 为什么不直接使用Lucene？ 但是Lucene仅仅只是一个库，你需要使用Java并将Lucene直接集成到应用程序中 您可能需要获得信息检索学位才能了解其工作原理，因为Lucene非常复杂 ES也是使用Java编写的，它的内部使用Lucene做索引与搜索 它的目的是隐藏Lucene的复杂性，取而代之的提供一套简单一致的RESTful API 1.2. ES主要功能 分布式实时文件存储，处理的结构化和非结构数据 实时分析的分布式搜索引擎，为用户提供关键字查询的全文检索功能 是实现企业级PB级海量数据处理分析的大数据解决方案（ELK） ES主要致力于结构化和非结构化数据的分布式实时全文搜索及分析，使用场景 日志管理与分析（ELK） 系统指标分析 安全分析 企业搜索（OA、CRM、ERP） 网站搜索（电商、招聘、门户） 应用搜索 应用性能管理APM 2. ES主要特点 2.1. 分片与集群 ES默认把数据分成多个片，多个片可以组成一个完整的数据，这些片可以分布在集群中的各个机器节点中 随着后期数据的越来越大，ES集群可以增加多个分片，把多个分片分散到更多的主机节点上 ES集群可以增加多个分片，把多个分片分散到更多的机器主机节点上，负责负载均衡，横向扩展 而每个查询任务提交到某一个节点，该节点必须负责将数据进行整理汇聚，再返回给客户端 2.2. 自动索引 ES所有数据默认都是索引的 ES只有不加索引才需要额外处理 2.3. 搜索是近实时的 你往 es 里写的数据，实际上都写到磁盘文件里去了 查询的时候，操作系统会将磁盘文件里的数据自动缓存到 filesystem cache 里面去。 es 的搜索引擎严重依赖于底层的 filesystem cache，你如果给 filesystem cache 更多的内存 尽量让内存可以容纳所有的idx segment file索引数据文件，那么你搜索的时候就基本都是走内存的，性能会非常高。 性能差距究竟可以有多大？我们之前很多的测试和压测： 如果走磁盘一般肯定上秒，搜索性能绝对是秒级别的，1秒、5秒、10秒。 但如果是走 filesystem cache，是走纯内存的，那么一般来说性能比走磁盘要高一个数量级，基本上就是毫秒级的，从几毫秒到几百毫秒不等。 2.4. ES优缺点 3. ES核心概念 mysql elasticsearch 数据库（Datebase） 索引（Index） 表（Table） 类型（Type） 行（Row）每一条 文档（Document）每一条 字段 属性 对象（Schema） 映射（Mapping） 索引（Index） 万物皆索引（不管什么数据都默认索引） SQL语言（Select、update） Query DSL（GET、PUT） 3.1. 索引（index）库 ES将他的数据存储在一个或多个索引中，可以向索引读写文档 索引相当于关系型数据库中的一个数据库 3.2. 类型（type）表 类型（type）是用来规定文档的各个字段内容的数据类型和其他的一些约束 一个索引（index）可以有多个文档类型（type） 文档类型（type）相当于关系型数据库中的表 3.3. 文档（document）行 在ES中，文档（document）是存储数据库的载体，包含一个或多个字段 ES中的最小的，整体的数据单位 文档（document）相当于关系型数据库中的一行数据 一个document里面有多个field，每个field就是一个数据字段 3.4. Lucene Index 注意和ES Index区别，Lucene Index是由若干段和提交点文件组成 3.5. 段（Segment） Luncene里面的一个数据集概念，因为ES底层是基于Lucene 最核心的概念就是Segment，每个段本身就是一个倒排索引 3.6. 提交点（commit point） 有一个列表存放着所有已知的所有段 3.7. 映射 映射是定义ES对索引中字段的存储类型，分词方式和是否存储等信息 就像数据库中的Schema，描述了文档可能具有的字段或属性，每个字段的数据类型 Es对字段类型可以不指定，然后动态对字段类型猜测 也可以在创建索引时具体指定字段的类型（关系型数据库才需要手动指定） 3.8. Shard 分片 单台机器无法存储大量数据，es可以将一个索引中的数据切分为多个shard，分布在多台服务器上存储 有了shard就可以横向扩展，存储更多数据，让搜索和分析等操作分布到多台服务器上去执行，提升吞吐量和性能 每个shard都是一个lucene index 3.9. Replica 副本 任何一个服务器随时可能故障或宕机，此时shard可能就会丢失，因此可以为每个shard创建多个replica副本 replica可以在shard故障时提供备用服务，保证数据不丢失，多个replica还可以提升搜索操作的吞吐量和性能 primary shard（建立索引时一次设置，不能修改，默认5个），replica shard（随时修改数量，默认1个） 默认每个索引10个shard，5个primary shard，5个replica shard，最小的高可用配置，是2台服务器 3.10. Cluster集群 包含多个节点，每个节点属于哪个集群是通过一个配置（集群名称，默认是elasticsearch）来决定的 对于中小型应用来说，刚开始一个集群就一个节点很正常 3.11. Node节点 集群的一个节点，节点也有一个名称（默认是随机分配的），节点名称很重要（在执行运维管理操作的时候） 默认节点会去加入一个名称为“elasticsearch”的集群，如果直接启动一堆节点，那么它们会自动组成一个elasticsearch集群 当然一个节点也可以组成一个elasticsearch集群 4. ES使用 4.1. 分片的设定 分片数过小，数据写入形成瓶颈，无法水平拓展 分片数过多，每个分片都是一个lucene的索引，分片过多将会占用过多资源 如何计算分片数 分片数量最好设置为节点数的整数倍，保证每一个主机的负载是差不多一样的 否则可能遇到其他主机负载正常，就某个主机负载特别高的情况 一般我们根据每天的数据量来计算分片，保持每个分片的大小在 50G 以下比较合理 如果还不能满足要求，那么可能需要在索引层面通过拆分更多的索引或者通过别名 + 按小时 创建索引 4.2. ES数据近实时问题 ES数据写入之后，要经过一个refresh操作之后，才能够创建索引，进行查询 但是get查询很特殊，数据实时可查 get查询的实时性，通过每次get查询的时候 如果发现该id还在内存中没有创建索引，那么首先会触发refresh操作，来让id可查 ES5.0之前translog可以提供实时的CRUD get查询会首先检查translog中有没有最新的修改，然后再尝试去segment中对id进行查找 5.0之后，为了减少translog设计的复杂性以便于再其他更重要的方面对translog进行优化 所以取消了translog的实时查询功能 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"docker-an-zhuang-es.html":{"url":"docker-an-zhuang-es.html","title":"Docker安装es","keywords":"","body":" Docker安装es1. 基于Docker安装Elasticsearch1.1. 创建网络1.2. 拉取镜像1.3. 创建挂载点目录1.4. 部署单点es，创建es容器1.5. 进入es容器1.6. 重启es容器2. 基于Docker安装Kibana2.1. 创建挂载点目录2.2. 部署kibana，创建kibana容器2.3. 测试Kibana是否安装成功 Docker安装es 1. 基于Docker安装Elasticsearch 1.1. 创建网络 因为需要部署kibana容器，因此需要让es和kibana容器互联。 docker network create es-net 1.2. 拉取镜像 以安装Elasticsearch 8.6.0 版本为例 docker pull elasticsearch:8.6.0 1.3. 创建挂载点目录 mkdir -p ./es/data ./es/config ./es/plugins 变为可执行文件 chmod 777 ./es/data chmod 777 ./es/config chmod 777 ./es/plugins 1.4. 部署单点es，创建es容器 docker run -d \\ --restart=always \\ --name es \\ --network es-net \\ -p 9200:9200 \\ -p 9300:9300 \\ --privileged \\ -v /Users/wyx/MyFile/Docker/es/data:/usr/share/elasticsearch/data \\ -v /Users/wyx/MyFile/Docker/es/plugins:/usr/share/elasticsearch/plugins \\ -e \"discovery.type=single-node\" \\ -e \"ES_JAVA_OPTS=-Xms512m -Xmx512m\" \\ elasticsearch:8.6.0 1.5. 进入es容器 docker exec -it es /bin/bash 编写elasticsearch.yml 跳转到config目录下 cd config echo 'xpack.security.enabled: false' >> elasticsearch.yml echo 'xpack.security.http.ssl.enabled: false' >> elasticsearch.yml 重置密码 记住New value: **0000000 docker exec -it elasticsearch1 /bin/bash 启用密码 想启用密码打开即可 xpack.security.enabled: true 设置 JVM 内存参数(可选设置) docker exec -it elasticsearch1 /bin/bash vi /usr/share/elasticsearch/config/jvm.options修改如下配置： ################################################################ ## IMPORTANT: JVM heap size ################################################################ ## ## The heap size is automatically configured by Elasticsearch ## based on the available memory in your system and the roles ## each node is configured to fulfill. If specifying heap is ## required, it should be done through a file in jvm.options.d, ## which should be named with .options suffix, and the min and ## max should be set to the same value. For example, to set the ## heap to 4 GB, create a new file in the jvm.options.d ## directory containing these lines: ## ## -Xms4g ## -Xmx4g ## ## See https://www.elastic.co/guide/en/elasticsearch/reference/8.9/heap-size.html ## for more information ## ################################################################ -Xms1g -Xmx1g 基于Docker安装IK分词器 注意：安装IK分词器的版本，必须和Elasticsearch的版本一致， 上文安装的是Elasticsearch 8.6.0的，所以接下来安装的IK分词器版本是8.6.0 直接执行即可 ./bin/elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v8.6.0/elasticsearch-analysis-ik-8.6.0.zip 如果需要安装其他版本的IK分词器，需要把版本号修改即可 ./bin/elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.4.2/elasticsearch-analysis-ik-7.4.2.zip ./bin/elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v8.6.0/elasticsearch-analysis-ik-8.6.0.zip 1.6. 重启es容器 docker restart es 测试 http://localhost:9200 2. 基于Docker安装Kibana docker pull kibana:8.6.0 2.1. 创建挂载点目录 mkdir -p ./kibana/config ./kibana/data chmod 777 /usr/local/kibana/data chmod 777 /usr/local/kibana/config 2.2. 部署kibana，创建kibana容器 docker run -d \\ --restart=always \\ --name kibana \\ --network es-net \\ -p 5601:5601 \\ -e ELASTICSEARCH_HOSTS=http://es:9200 \\ kibana:8.6.0 2.3. 测试Kibana是否安装成功 访问虚拟机地址+端口号，前面配置Kibana 的端口号为：5601 http://localhost:5601\\ console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"es-ji-ben-yu-fa.html":{"url":"es-ji-ben-yu-fa.html","title":"ES基本语法","keywords":"","body":" ES基本语法1.1. 概念1.2. 基本语法 ES基本语法 1.1. 概念 索引（Index）文档 PUT /索引名称/_doc/文档ID { \"field1\": \"value1\", \"field2\": \"value2\", ... } 获取（Get）文档 GET /索引名称/_doc/文档ID 更新（Update）文档 POST /索引名称/_update/文档ID { \"doc\": { \"field1\": \"new_value1\", \"field2\": \"new_value2\", ... } } 删除（Delete）文档 DELETE /索引名称/_doc/文档ID 搜索（Search）文档 GET /索引名称/_search { \"query\": { \"match\": { \"field\": \"value\" } } } 这些语句中的关键点解释如下： /索引名称：指定要操作的索引名称。 /_doc：指定文档类型，从 Elasticsearch 7.x 版本开始，默认类型为 _doc。 /文档ID：指定要操作的文档的唯一标识符。 在实际使用中，你需要将这些语句中的占位符替换为你实际的索引名称、文档ID和字段值。 请注意，Elasticsearch 还提供了更多高级的查询和操作功能，例如聚合、过滤器等。以上只是一些基本的示例，你可以根据具体需求进行更复杂的查询和操作。 1.2. 基本语法 // 获取所有 GET /_search { \"took\": 410, \"timed_out\": false, \"_shards\": { \"total\": 1, \"successful\": 1, \"skipped\": 0, \"failed\": 0 }, \"hits\": { \"total\": { \"value\": 0, \"relation\": \"eq\" }, \"max_score\": null, \"hits\": [] } } 1 took：耗费了几毫秒 2 timed_out：是否超时，false是没有，默认无timeout 3 _shards：shards fail的条件（primary和replica全部挂掉），不影响其他shard。默认情况下来说，一个搜索请求，会打到一个index的所有primary shard上去，当然了，每个primary shard都可能会有一个或多个replic shard，所以请求也可以到primary shard的其中一个replica shard上去。 4 hits.total：本次搜索，返回了几条结果 5 hits.max_score：score的含义，就是document对于一个search的相关度的匹配分数，越相关，就越匹配，分数也高 6 hits.hits：包含了匹配搜索的document的详细数据，默认查询前10条数据，按_score降序排序 创建索引 // 创建索引 PUT /test_es { \"mappings\": { \"properties\": { \"name\": { \"type\": \"text\", \"fields\": { \"keyword\": { \"type\": \"keyword\" } } }, \"age\": { \"type\": \"integer\" }, \"email\": { \"type\": \"keyword\" }, \"date_of_birth\": { \"type\": \"date\" }, \"address\": { \"type\": \"nested\", \"properties\": { \"street\": { \"type\": \"text\" }, \"city\": { \"type\": \"text\" }, \"country\": { \"type\": \"keyword\" } } } } } } { \"acknowledged\": true, \"shards_acknowledged\": true, \"index\": \"test_es\" } 创建值 // 为索引添加值 POST /test_es/_doc/1 { \"name\": \"John\", \"age\": 30, \"email\": \"john@example.com\", \"date_of_birth\": \"1990-01-01\", \"address\": { \"street\": \"123 Main St\", \"city\": \"New York\", \"country\": \"USA\" } } POST /test_es/_doc/2 { \"name\": \"Jane\", \"age\": 25, \"email\": \"jane@example.com\", \"date_of_birth\": \"1995-05-10\", \"address\": { \"street\": \"456 Elm St\", \"city\": \"London\", \"country\": \"UK\" } } { \"_index\": \"test_es\", \"_id\": \"1\", \"_version\": 1, \"result\": \"created\", \"_shards\": { \"total\": 2, \"successful\": 1, \"failed\": 0 }, \"_seq_no\": 0, \"_primary_term\": 1 } 条件查询 // 查询 GET /test_es/_search { \"query\": { \"match\": { \"name\": \"John\" } } } { \"took\": 475, \"timed_out\": false, \"_shards\": { \"total\": 1, \"successful\": 1, \"skipped\": 0, \"failed\": 0 }, \"hits\": { \"total\": { \"value\": 1, \"relation\": \"eq\" }, \"max_score\": 0.6931471, \"hits\": [ { \"_index\": \"test_es\", \"_id\": \"1\", \"_score\": 0.6931471, \"_source\": { \"name\": \"John\", \"age\": 30, \"email\": \"john@example.com\", \"date_of_birth\": \"1990-01-01\", \"address\": { \"street\": \"123 Main St\", \"city\": \"New York\", \"country\": \"USA\" } } } ] } } 修改 // 修改 POST /test_es/_update/1 { \"doc\": { \"age\": 35 } } { \"_index\": \"test_es\", \"_id\": \"1\", \"_version\": 2, \"result\": \"updated\", \"_shards\": { \"total\": 2, \"successful\": 1, \"failed\": 0 }, \"_seq_no\": 2, \"_primary_term\": 1 } 删除 // 删除 DELETE /test_es/_doc/1 { \"_index\": \"test_es\", \"_id\": \"1\", \"_version\": 3, \"result\": \"deleted\", \"_shards\": { \"total\": 2, \"successful\": 1, \"failed\": 0 }, \"_seq_no\": 3, \"_primary_term\": 1 } console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"es-yu-fa-jin-jie.html":{"url":"es-yu-fa-jin-jie.html","title":"ES语法进阶（📌）","keywords":"","body":" ES语法进阶（&#x1F4CC;）1. url参数搜索1.1. 查询所有1.2. 多索引，多type搜索1.3. 按条件查询1.4. 查询DSL1.5. 复合查询2. 查询示例2.1. 获取所有2.2. 分页查询2.3. 指定查询出来的数据返回的字段2.4. ad字段中包含单词white2.5. ad字段中包含单词white，并按照价格升序排列2.6. 价格字段大于50002.7. ad字段中包含单词white，价格字段大于50002.8. 查询name字段包含单词phone的文档的数量3. 关键词详解3.1. match_all查询3.2. match查询3.3. multi_match查询3.4. range查询3.5. term查询3.6. terms查询3.7. exists 查询和 missing 查询3.8. match_phrase查询3.9. scroll查询3.10. multi get查询3.11. bulk批量操作3.12. fuzzy查询3.13. wildcard查询 ES语法进阶（&#x1F4CC;） 1. url参数搜索 这种方式就是类似于get请求，将请求参数拼接到链接上，例GET /school/student/_search?参数，多个参数用&分开 1.1. 查询所有 命令：GET /school/student/_search 返回： { \"took\": 7, //查询耗时，毫秒 \"timed_out\": false, //是否超时，timeout 不是停止执行查询，它仅仅是告知正在协调的节点返回到目前为止收集的结果并且关闭连接 \"_shards\": { \"total\": 5, //请求的分片数量，索引拆成了5个分片，所以对于搜索请求，会打到所有的primary shard \"successful\": 5, \"skipped\": 0, \"failed\": 0 }, \"hits\": { \"total\": 2, //符合条件的总条数，这里查的是所有 \"max_score\": 1, //匹配分数 \"hits\": [ //数据 { \"_index\": \"school\", \"_type\": \"student\", \"_id\": \"2\", \"_score\": 1, \"_source\": { \"name\": \"houyi\", \"age\": 23, \"class\": 2, \"gender\": \"男\" } }, { \"_index\": \"school\", \"_type\": \"student\", \"_id\": \"1\", \"_score\": 1, \"_source\": { \"name\": \"吕布\", \"age\": 21, \"class\": 2, \"gender\": \"男\" } } ] } } 1.2. 多索引，多type搜索 在URL中指定特殊的索引和类型进行多索引，多type搜索 /_search：在所有的索引中搜索所有的类型 /school/_search：在 school 索引中搜索所有的类型 /school,ad/_search：在 school 和ad索引中搜索所有的类型 /s*,a*/_search：在所有以g和a开头的索引中所有所有的类型 /school/student/_search：在school索引中搜索student类型 /school,ad/student,phone/_search：在school和ad索引上搜索student和phone类型 /_all/student,phone/_search：在所有的索引中搜索student和phone类型 1.3. 按条件查询 命令：GET /school/student/_search?q=name:houyi 查询name是houyi的记录 更多查询参数： 1.4. 查询DSL elasticsearch提供了基于JSON的完整查询DSL来定义查询，DSL拥有一套查询组件，这些组件可以以无限组合的方式进行搭配，构建各种复杂的查询 叶子语句 叶子语句：就像match语句，被用于将查询的字符串与一个字段或多个字段进行对比（单个条件） 比如： GET /ad/phone/_search { \"query\": { \"match\": { \"name\": \"phone\" } } } 1.5. 复合查询 用户合并其他查询语句，比如一个bool语句，允许你在需要的时候组合其他语句，包括must，must_not，should和filter语句（多条件组合查询） 比如： GET /ad/phone/_search { \"query\": { \"bool\": { \"must\": [ {\"match\": { \"name\": \"phone\" }} ] , \"must_not\": [ {\"match\": { \"color\": \"red\" }} ] , \"should\": [ {\"match\": { \"price\": 5000 }} ] , \"filter\": { \"term\": { \"label\": \"phone\" } } } } } must：表示文档一定要包含查询的内容 must_not：表示文档一定不要包含查询的内容 should：表示如果文档匹配上可以增加文档相关性得分 事实上我们可以使用两种结构化语句： 结构化查询query DSL和结构化过滤Filter DSL 结构化查询query DSL 用于检查内容与条件是否匹配，内容查询中使用的bool和match字句，用于计算每个文档的匹配得分，元字段_score表示匹配度，查询的结构中以query参数开始来执行内容查询 结构化过滤Filter DSL 只是简单的决定文档是否匹配，内容过滤中使用的term和range字句，会过滤 调不匹配的文档，并且不影响计算文档匹配得分 使用过滤查询会被es自动缓存用来提高效率 原则上来说，使用查询语句做全文本搜索或其他需要进行相关性评分的时候，剩下的全部用过滤语句 新建一个稍微复杂的索引，添加三条文档 PUT /ad/phone/1 { \"name\":\"phone 8\", \"price\": 6000, \"color\":\"white\", \"ad\":\"this is a white phone\", \"label\":[\"white\",\"nice\"] } PUT /ad/phone/2 { \"name\":\"xiaomi 8\", \"price\": 4000, \"color\":\"red\", \"ad\":\"this is a red phone\", \"label\":[\"white\",\"xiaomi\"] } PUT /ad/phone/3 { \"name\":\"huawei p30\", \"price\": 5000, \"color\":\"white\", \"ad\":\"this is a white phone\", \"label\":[\"white\",\"huawei\"] } 2. 查询示例 2.1. 获取所有 GET /ad/phone/_search { \"query\": { \"match_all\": {} } } match_all匹配所有数据，返回的结果中元字段_score得分为1 2.2. 分页查询 从第二条开始，查两条（不要使用from，size进行深度分页，会有性能问题） GET /ad/phone/_search { \"query\": { \"match_all\": {} }, \"from\": 1, \"size\": 2 } 这种分页方式如果进行深度分页，比如到100页，每页十条数据，它会从每个分片都查询出100*10条数据，假设有五个分片，就是5000条数据，然后在内存中进行排序，然后返回拍过序之后的集合中的第1000-1010条数据 2.3. 指定查询出来的数据返回的字段 GET /ad/phone/_search { \"query\": { \"match_all\": {} }, \"_source\": [\"name\",\"price\"] } 返回的数据中只返回name和price字段 2.4. ad字段中包含单词white GET /ad/phone/_search { \"query\": { \"match\": { \"ad\": \"white\" } } } 返回的结果中元字段_score有评分，说明使用query会计算评分 2.5. ad字段中包含单词white，并按照价格升序排列 GET /ad/phone/_search { \"query\": { \"match\": { \"ad\": \"white\" } }, \"sort\": [ { \"price\": { \"order\": \"asc\" } } ] } 2.6. 价格字段大于5000 GET /ad/phone/_search { \"query\": { \"bool\": { \"filter\": { \"range\": { \"price\": { \"gt\": 5000 } } } } } } 返回的结果中元字段_score字段等于0，没评分，说明使用filter不会计算评分 2.7. ad字段中包含单词white，价格字段大于5000 GET /ad/phone/_search { \"query\": { \"bool\": { \"must\": [ { \"match\": { \"ad\": \"white\" } } ], \"filter\": { \"range\": { \"price\": { \"gt\": 5000 } } } } } } 2.8. 查询name字段包含单词phone的文档的数量 GET /ad/phone/_count { \"query\": { \"match\": { \"name\": \"phone\" } } } 3. 关键词详解 3.1. match_all查询 查询简单的匹配所有文档 GET /ad/phone/_search { \"query\": { \"match_all\": {} } } 3.2. match查询 支持全文搜索和精确查询，取决于字段是否支持全文检索 全文检索： GET /ad/phone/_search { \"query\": { \"match\": { \"ad\": \"a red\" } } } 全文检索会将查询的字符串先进行分词，a red会分成为a和red，然后在倒排索引中进行匹配，所以这条语句会将三条文档都查出来 精确查询： GET /ad/phone/_search { \"query\": { \"match\": { \"price\": \"6000\" } } } 对于精确值的查询，可以使用 filter 语句来取代 query，因为 filter 将会被缓存 operator操作： match 查询还可以接受 operator 操作符作为输入参数，默认情况下该操作符是 or 。我们可以将它修改成 and 让所有指定词项都必须匹配 GET /ad/phone/_search { \"query\": { \"match\": { \"ad\": { \"query\": \"a red\", \"operator\": \"and\" } } } } 精确度匹配： match 查询支持 minimum_should_match 最小匹配参数， 可以指定必须匹配的词项数用来表示一个文档是否相关。我们可以将其设置为某个具体数字（指需要匹配倒排索引的词的数量），更常用的做法是将其设置为一个百分数，因为我们无法控制用户搜索时输入的单词数量 GET /ad/phone/_search { \"query\": { \"match\": { \"ad\": { \"query\": \"a red\", \"minimum_should_match\": \"2\" } } } } 只会返回匹配上a和red两个词的文档返回，如果minimum_should_match是1，则只要匹配上其中一个词，文档就会返回 3.3. multi_match查询 多字段查询，比如查询color和ad字段包含单词red的文档 GET /ad/phone/_search { \"query\": { \"multi_match\": { \"query\": \"red\", \"fields\": [\"color\",\"ad\"] } } } 3.4. range查询 范围查询，查询价格大于4000小于6000的文档 GET /ad/phone/_search { \"query\": { \"range\": { \"price\": { \"gt\": 4000, \"lt\": 6000 } } } } 范围查询操作符：gt （大于），gte（大于等于），lt（小于），lte（小于等于)； 3.5. term查询 精确值查询 查询price字段等于6000的文档 GET /ad/phone/_search { \"query\": { \"term\": { \"price\": { \"value\": \"6000\" } } } } 查询name字段等于phone 8的文档 GET /ad/phone/_search { \"query\": { \"term\": { \"name\": { \"value\": \"phone 8\" } } } } 返回值如下，没有查询到名称为phone 8的文档 { \"took\": 5, \"timed_out\": false, \"_shards\": { \"total\": 5, \"successful\": 5, \"skipped\": 0, \"failed\": 0 }, \"hits\": { \"total\": 0, \"max_score\": null, \"hits\": [] } } 为什么没有查到phone 8的这个文档那，这里需要介绍一下term的查询原理 ​ term查询会去倒排索引中寻找确切的term,它并不会走分词器，只会去配倒排索引 ，而name字段的type类型是text，会进行分词，将phone 8 分为phone和8，我们使用term查询phone 8时倒排索引中没有phone 8，所以没有查询到匹配的文档 term查询与match查询的区别 term查询时，不会分词，直接匹配倒排索引 match查询时会进行分词，查询phone 8时，会先分词成phone和8，然后去匹配倒排索引，所以结果会将phone 8和xiaomi 8两个文档都查出来 还有一点需要注意，因为term查询不会走分词器，但是回去匹配倒排索引，所以查询的结构就跟分词器如何分词有关系，比如新增一个/ad/phone类型下的文档，name字段赋值为Oppo，这时使用term查询Oppo不会查询出文档，这时因为es默认是用的standard分词器，它在分词后会将单词转成小写输出，所以使用oppo查不出文档，使用小写oppo可以查出来 GET /ad/phone/_search { \"query\": { \"term\": { \"name\": { \"value\": \"Oppo\" //改成oppo可以查出新添加的文档 } } } } 这里说的并不是想让你了解standard分词器，而是要get到所有像term这类的查询结果跟选择的分词器有关系，了解选择的分词器分词方式有助于我们编写查询语句 3.6. terms查询 terms查询与term查询一样，但它允许你指定多直进行匹配，如果这个字段包含了指定值中的任何一个值，那么这个文档满足条件 GET /ad/phone/_search { \"query\": { \"terms\": { \"ad\": [\"red\",\"blue\"] } } } 3.7. exists 查询和 missing 查询 用于查找那些指定字段中有值 (exists) 或无值 (missing) 的文档 指定name字段有值： GET /ad/phone/_search { \"query\": { \"bool\": { \"filter\": { \"exists\": { \"field\": \"name\" } } } } } 指定name字段无值： GET /ad/phone/_search { \"query\": { \"bool\": { \"filter\": { \"missing\": { \"field\": \"name\" } } } } } 3.8. match_phrase查询 短语查询，精确匹配，查询a red会匹配ad字段包含a red短语的，而不会进行分词查询，也不会查询出包含a 其他词 red这样的文档 GET /ad/phone/_search { \"query\": { \"match_phrase\": { \"ad\": \"a red\" } } } 3.9. scroll查询 类似于分页查询，不支持跳页查询，只能一页一页往下查询，scroll查询不是针对实时用户请求，而是针对处理大量数据，例如为了将一个索引的内容重新索引到具有不同配置的新索引中 POST /ad/phone/_search?scroll=1m { \"query\": { \"match_all\": {} }, \"size\": 1, \"from\": 0 } 返回值包含一个 \"_scroll_id\": \"DnF1ZXJ5VGhlbkZldGNoBQAAAAAAAAAQFlV6T3VqY2NaVDBLRG5uZXdiZ0hFYUEAAAAAAAAAERZVek91amNjWlQwS0RubmV3YmdIRWFBAAAAAAAAABIWVXpPdWpjY1pUMEtEbm5ld2JnSEVhQQAAAAAAAAATFlV6T3VqY2NaVDBLRG5uZXdiZ0hFYUEAAAAAAAAAFBZVek91amNjWlQwS0RubmV3YmdIRWFB\" 下次查询的时候使用_scroll_id就可以查询下一页的文档 POST /_search/scroll { \"scroll\" : \"1m\", \"scroll_id\" : \"DnF1ZXJ5VGhlbkZldGNoBQAAAAAAAAAYFlV6T3VqY2NaVDBLRG5uZXdiZ0hFYUEAAAAAAAAAGRZVek91amNjWlQwS0RubmV3YmdIRWFBAAAAAAAAABYWVXpPdWpjY1pUMEtEbm5ld2JnSEVhQQAAAAAAAAAXFlV6T3VqY2NaVDBLRG5uZXdiZ0hFYUEAAAAAAAAAFRZVek91amNjWlQwS0RubmV3YmdIRWFB\" } 3.10. multi get查询 允许基于索引，类型（可选）和id（以及可能的路由）获取多个文档，如果某个文档获取失败则将错误信息包含在响应中 GET /ad/phone/_mget { \"ids\": [\"1\",\"8\"] } ``` 3.11. bulk批量操作 bulk批量操作可以在单次API调用中实现多个文档的create、index、update或delete。这可以大大提高索引速度 bulk请求体如下 { action: { metadata }}\\n { request body }\\n { action: { metadata }}\\n { request body }\\n ... action必须是以下几种： 行为 解释 create 当文档不存在时创建 index 创建新文档或替换已有文档 update 局部更新文档 delete 删除一个文档 在索引、创建、更新或删除时必须指定文档的_index、_type、_id这些元数据(metadata) 例： PUT _bulk { \"create\" : { \"_index\" : \"ad\", \"_type\" : \"phone\", \"_id\" : \"6\" }} { \"doc\" : {\"name\" : \"bulk\"}} { \"index\" : { \"_index\" : \"ad\", \"_type\" : \"phone\", \"_id\" : \"6\" }} { \"doc\" : {\"name\" : \"bulk\"}} { \"delete\":{ \"_index\" : \"ad\", \"_type\" : \"phone\", \"_id\" : \"1\"}} { \"update\":{ \"_index\" : \"ad\", \"_type\" : \"phone\", \"_id\" : \"3\"}} { \"doc\" : {\"name\" : \"huawei p20\"}} 返回： { \"took\": 137, \"errors\": true, //如果任意一个文档出错，这里返回true, \"items\": [ //items数组，它罗列了每一个请求的结果，结果的顺序与我们请求的顺序相同 { //create这个文档已经存在，所以异常 \"create\": { \"_index\": \"ad\", \"_type\": \"phone\", \"_id\": \"6\", \"status\": 409, \"error\": { \"type\": \"version_conflict_engine_exception\", \"reason\": \"[phone][6]: version conflict, document already exists (current version [2])\", \"index_uuid\": \"9F5FHqgISYOra_P09HReVQ\", \"shard\": \"2\", \"index\": \"ad\" } } }, { //index这个文档已经存在，会覆盖 \"index\": { \"_index\": \"ad\", \"_type\": \"phone\", \"_id\": \"6\", \"_version\": 3, \"result\": \"updated\", \"_shards\": { \"total\": 2, \"successful\": 1, \"failed\": 0 }, \"_seq_no\": 6, \"_primary_term\": 5, \"status\": 200 } }, { //删除 \"delete\": { \"_index\": \"ad\", \"_type\": \"phone\", \"_id\": \"1\", \"_version\": 1, \"result\": \"not_found\", \"_shards\": { \"total\": 2, \"successful\": 1, \"failed\": 0 }, \"_seq_no\": 4, \"_primary_term\": 5, \"status\": 404 } }, { //修改 \"update\": { \"_index\": \"ad\", \"_type\": \"phone\", \"_id\": \"3\", \"_version\": 3, \"result\": \"noop\", \"_shards\": { \"total\": 2, \"successful\": 1, \"failed\": 0 }, \"status\": 200 } } ] } bulk请求不是原子操作，它们不能实现事务。每个请求操作时分开的，所以每个请求的成功与否不干扰其它操作 3.12. fuzzy查询 模糊查询，fuzzy 查询会计算与关键词的拼写相似程度 GET /ad/phone/_search { \"query\": { \"fuzzy\": { \"color\":{ \"value\": \"res\" , \"fuzziness\": 2, \"prefix_length\": 1 } } } } 参数设置： fuzziness：最大编辑距离，默认为AUTO prefix_length：不会“模糊化”的初始字符数。这有助于减少必须检查的术语数量，默认为0 max_expansions：fuzzy查询将扩展到 的最大术语数。默认为50，设置小，有助于优化查询 transpositions：是否支持模糊转置（ab→ ba），默认是false 3.13. wildcard查询 支持通配符的模糊查询，？匹配单个字符，*匹配任何字符 为了防止极其缓慢通配符查询，*或?通配符项不应该放在通配符的开始 GET /ad/phone/_search { \"query\": { \"wildcard\": { \"color\": \"r?d\" } } } console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"dao-pai-suo-yin.html":{"url":"dao-pai-suo-yin.html","title":"倒排索引","keywords":"","body":" 倒排索引1. 倒排索引原理 1.1. Lucene索引构成 1.2. Posting List 倒排列表 1.3. Term Index 词项索引 1.4. Term Dictionary 词项字典 1.5. 总结 2. 如何联合索引查询 2.1. 查询合并 2.2. Skip List 合并 2.3. bitset合并 2.4. 如何减少文档数 倒排索引 1. 倒排索引原理 1.1. Lucene索引构成 Lucene索引由下面三部分构成构成 1）Term Index（词项索引） Term Index是一个索引结构，用于快速查找Term Dictionary中的词项 Term Index通常是用Trie树（也称为 前缀树，字典树）实现的 在Trie树中，每个节点代表一个字符串（前缀），每条边代表一个字符 从根节点到叶子节点的路径代表一个完整的字符串 当我们查找一个词项时，可以从根节点开始，沿着词项的每个字符对应的边找下去 直到找到词项或确定词项不存在 2）Term Dictionary（词项字典） Term Dictionary是所有索引词项的集合 每个词项都关联着一个Posting List 词项字典一般会存储词项的相关信息，如词项的文档频率等 3）Posting List（倒排列表） Posting List是包含了某个词项的所有文档的ID列表 每个Posting List一般会包含词项频率、位置信息、偏移信息 查找过程 在构建索引时，首先会对文档进行分词处理，得到一系列的词项 然后将这些词项添加到词项字典中，并更新相关的Posting List 在此过程中，还会更新Term Index，以保证可以快速定位到词项字典中的词项 在进行搜索时，首先会在Term Index中查找词项 然后通过Term Dictionary找到对应的Posting List，从而找到包含该词项的所有文档 1.2. Posting List 倒排列表 [1,2,3]是Posting List（倒排列表） 0）我们有如下4 条文档数据 文档ID 文档内容 1 人工智能成为互联网大会焦点 2 谷歌推出开源人工智能系统工具 3 互联网的未来在人工智能 4 谷歌开源机器学习工具 1）分词 对于文档内容，先要经过词条化处理 与英文不同的是，英文通过空格分隔单词(中文需要分词工具) 经过分词系统进行中文分词以后把矩阵切分成一个个的词条 2）给这些document建立的倒排索引如下 人工，智能叫做Term（词项） ES会将文档的内容分词，每个分词就是一个词项 [1,2,3]是Posting List（倒排列表） ES会为每个词项建立一个\"Posting List” 倒排列表是指包含了一个词项的所有文档的ID列表 第一条\"[1,2,3]\"，表示词项“人工”在文档1,2,3 中都出现过 词项 文档频率 倒排记录表 人工 3 1,2,3 智能 3 1,2,3 成为 1 1 互联网 2 1,3 大会 1 1 焦点 1 1 谷歌 2 2,4 推出 1 2 1.3. Term Index 词项索引 Term Index是一个索引结构，用于快速查找Term Dictionary中的词项 Term Index通常是用Trie树（也称为前缀树）实现的 在Trie树中，每个节点代表一个字符串（前缀），每条边代表一个字符 从根节点到叶子节点的路径代表一个完整的字符串 当我们查找一个词项时，可以从根节点开始 沿着词项的每个字符对应的边找下去，直到找到词项或确定词项不存在 下面是一个包含 \"A\", \"to\", \"tea\", \"ted\", \"ten\", \"i\", \"in\", 和 \"inn\" 的 trie 树 这棵树不会包含所有的term，它包含的是term的一些前缀 通过term index可以快速地定位到term dictionary的某个offset，然后从这个位置再往后顺序查找 再加上一些压缩技术term index 的尺寸可以只有所有term的尺寸的几十分之一 使得用内存缓存整个term index变成可能 1.4. Term Dictionary 词项字典 Term Dictionary是所有索引词项的集合 每个词项都关联着一个Posting List 词项字典一般会存储词项的相关信息，如词项的文档频率等 1.5. 总结 1）为什么 ES 比 MySQL 快 Mysql只有term dictionary这一层，是以b-tree排序的方式存储在磁盘上的 检索一个term需要若干次的random access的磁盘操作 而Lucene在term dictionary的基础上添加了term index来加速检索，term index以树的形式缓存在内存中 从term index查到对应的term dictionary的block位置之后，再去磁盘上找term，大大减少了磁盘的random access次数 2）FST（finite state transducers） term index在内存中是以FST（finite state transducers）的形式保存的，其特点是非常节省内存 Term dictionary在磁盘上是以分block的方式保存的，一个block内部利用公共前缀压缩 比如都是Ab开头的单词就可以把Ab省去。这样term dictionary可以比b-tree更节约磁盘空间 2. 如何联合索引查询 2.1. 查询合并 如何过滤 age=18 AND gender=女 的文档 给定查询过滤条件 age=18 的过程就是先从term index找到18在term dictionary的大概位置 然后再从term dictionary里精确地找到18这个term，然后得到一个posting list或者一个指向posting list位置的指针 然后再查询 gender=女 的过程也是类似的 最后得出 age=18 AND gender=女 就是把两个 posting list 做一个“与”的合并 如何将两个索引结构合并提供了两种方法 使用skip list数据结构。同时遍历gender和age的posting list，互相skip 使用bitset数据结构，对gender和age两个filter分别求出bitset，对两个bitset做AN操作 2.2. Skip List 合并 以上是三个posting list，我们现在需要把它们用AND的关系合并，得出posting list的交集 首先选择最短的posting list，然后从小到大遍历 遍历的过程可以跳过一些元素，比如我们遍历到绿色的13的时候，就可以跳过蓝色的3了，因为3比13要小 最后得出的交集是[13,98]，所需的时间比完整遍历三个posting list要快得多 但是前提是每个list需要指出Advance这个操作，快速移动指向的位置 2.3. bitset合并 # Bitset是一种很直观的数据结构，对应posting list如 [1,3,4,7,10] # 对应的bitset就是 [1,0,1,1,0,0,1,0,0,1] 每个文档按照文档id排序对应其中的一个bit，Bitset自身就有压缩的特点 其用一个byte就可以代表8个文档，所以100万个文档只需要12.5万个byte 但是考虑到文档可能有数十亿之多，在内存里保存bitset仍然是很奢侈的事情 而且对于个每一个filter都要消耗一个bitset，比如age=18缓存起来的话是一个bitset 18 所以秘诀就在于需要有一个数据结构 可以很压缩地保存上亿个bit代表对应的文档是否匹配filter 这个压缩的bitset仍然可以很快地进行AND和 OR的逻辑操作 Lucene使用的这个数据结构叫做 Roaring Bitmap 其压缩的思路其实很简单，与其保存100个0，占用100个bit 还不如保存0一次，然后声明这个0重复了100遍 2.4. 如何减少文档数 一种常见的压缩存储时间序列的方式是把多个数据点合并成一行 Opentsdb支持海量数据的一个绝招就是定期把很多行数据合并成一行，这个过程叫compaction 类似的vivdcortext使用mysql存储的时候，也把一分钟的很多数据点合并存储到mysql的一行里以减少行数 这个过程可以示例如下 Elasticsearch有一个功能可以实现类似的优化效果，那就是Nested Document 我们可以把一段时间的很多个数据点打包存储到一个父文档里，变成其嵌套的子文档 示例如下 {timestamp:12:05:01, idc:sz, value1:10,value2:11} {timestamp:12:05:02, idc:sz, value1:9,value2:9} {timestamp:12:05:02, idc:sz, value1:18,value:17} 可以打包成 { \"max_timestamp\": \"12:05:02\", \"min_timestamp\": \"1205:01\", \"idc\": \"sz\", \"records\": [ { \"timestamp\": \"12:05:01\", \"value1\": 10, \"value2\": 11 }, { \"timestamp\": \"12:05:02\", \"value1\": 9, \"value2\": 9 }, { \"timestamp\": \"12:05:02\", \"value1\": 18, \"value2\": 17 } ] } 这样可以把数据点公共的维度字段上移到父文档里，而不用在每个子文档里重复存储，从而减少索引的尺寸 如果我们可以在一个父文档里塞入50个嵌套文档，那么posting list可以变成之前的1/50 对于term的posting list只需要保存父文档的doc id，比保存所有的数据点的doc id要少很多 把父子关系也理解为一个filter，那么查询时检索的时候不过是又AND了另外一个filter而已 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"}}